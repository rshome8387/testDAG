24/01/10 06:30:51 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/01/10 06:30:53 WARN DependencyUtils: Local jar /mnt/var/lib/hadoop/steps/s-004642432GNVXAGO3NJB/s3:/quantexa-emr-logs-bucket-575193579798/emr/scripts/test-sparkscript/danske-markets-aml-data-generator-shadow-4.6.0-RC-2-projects.jar -s com.quantexa.danske.markets.aml.generators.AllDataGenerator -r config -e dev does not exist, skipping.
24/01/10 06:30:53 WARN DependencyUtils: Skip remote jar s3://quantexa-emr-logs-bucket-575193579798/emr/scripts/test-sparkscript/danske-markets-aml-data-generator-shadow-4.6.0-RC-2-projects.jar.
24/01/10 06:30:53 WARN DependencyUtils: Skip remote jar s3://quantexa-emr-logs-bucket-575193579798/emr/scripts/test-sparkscript/spark-avro_2.12-3.0.1.jar.
24/01/10 06:30:53 WARN DependencyUtils: Skip remote jar s3://quantexa-emr-logs-bucket-575193579798/emr/scripts/test-sparkscript/danske-markets-aml-data-generator-shadow-4.6.0-RC-2-dependency.jar.
24/01/10 06:30:54 INFO RMProxy: Connecting to ResourceManager at ip-10-170-137-72.eu-central-1.compute.internal/10.170.137.72:8032
24/01/10 06:30:54 INFO Client: Requesting a new application from cluster with 1 NodeManagers
24/01/10 06:30:54 INFO Configuration: resource-types.xml not found
24/01/10 06:30:54 INFO ResourceUtils: Unable to find 'resource-types.xml'.
24/01/10 06:30:54 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (12288 MB per container)
24/01/10 06:30:54 INFO Client: Will allocate AM container, with 2432 MB memory including 384 MB overhead
24/01/10 06:30:54 INFO Client: Setting up container launch context for our AM
24/01/10 06:30:54 INFO Client: Setting up the launch environment for our AM container
24/01/10 06:30:54 INFO Client: Preparing resources for our AM container
24/01/10 06:30:54 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.
24/01/10 06:30:57 INFO Client: Uploading resource file:/mnt/tmp/spark-bd8f2c25-8fbb-4bc2-b1b9-d02181510f3f/__spark_libs__5322346655241543217.zip -> hdfs://ip-10-170-137-72.eu-central-1.compute.internal:8020/user/hadoop/.sparkStaging/application_1701766556274_0040/__spark_libs__5322346655241543217.zip
24/01/10 06:31:00 INFO Client: Uploading resource file:/mnt/var/lib/hadoop/steps/s-004642432GNVXAGO3NJB/s3:/quantexa-emr-logs-bucket-575193579798/emr/scripts/test-sparkscript/danske-markets-aml-data-generator-shadow-4.6.0-RC-2-projects.jar -s com.quantexa.danske.markets.aml.generators.AllDataGenerator -r config -e dev -> hdfs://ip-10-170-137-72.eu-central-1.compute.internal:8020/user/hadoop/.sparkStaging/application_1701766556274_0040/danske-markets-aml-data-generator-shadow-4.6.0-RC-2-projects.jar -s com.quantexa.danske.markets.aml.generators.AllDataGenerator -r config -e dev
24/01/10 06:31:00 INFO Client: Deleted staging directory hdfs://ip-10-170-137-72.eu-central-1.compute.internal:8020/user/hadoop/.sparkStaging/application_1701766556274_0040
Exception in thread "main" java.io.FileNotFoundException: File file:/mnt/var/lib/hadoop/steps/s-004642432GNVXAGO3NJB/s3:/quantexa-emr-logs-bucket-575193579798/emr/scripts/test-sparkscript/danske-markets-aml-data-generator-shadow-4.6.0-RC-2-projects.jar -s com.quantexa.danske.markets.aml.generators.AllDataGenerator -r config -e dev does not exist
	at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:671)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:992)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:661)
	at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:464)
	at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:386)
	at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:337)
	at org.apache.spark.deploy.yarn.Client.copyFileToRemote(Client.scala:404)
	at org.apache.spark.deploy.yarn.Client.distribute$1(Client.scala:496)
	at org.apache.spark.deploy.yarn.Client.$anonfun$prepareLocalResources$20(Client.scala:599)
	at scala.Option.foreach(Option.scala:407)
	at org.apache.spark.deploy.yarn.Client.prepareLocalResources(Client.scala:598)
	at org.apache.spark.deploy.yarn.Client.createContainerLaunchContext(Client.scala:887)
	at org.apache.spark.deploy.yarn.Client.submitApplication(Client.scala:202)
	at org.apache.spark.deploy.yarn.Client.run(Client.scala:1236)
	at org.apache.spark.deploy.yarn.YarnClusterApplication.start(Client.scala:1643)
	at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:959)
	at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:180)
	at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:203)
	at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:90)
	at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1038)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1047)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
24/01/10 06:31:00 INFO ShutdownHookManager: Shutdown hook called
24/01/10 06:31:00 INFO ShutdownHookManager: Deleting directory /mnt/tmp/spark-bd8f2c25-8fbb-4bc2-b1b9-d02181510f3f
24/01/10 06:31:00 INFO ShutdownHookManager: Deleting directory /mnt/tmp/spark-90b6664a-f98c-49d5-902e-85752a4f8592
Command exiting with ret '1'
